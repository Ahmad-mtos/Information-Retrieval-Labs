# Lab 1

## Overview

The purpose of this notebook is to introduce essential skills for internet crawling, including regular expressions, working with streams and files, and using BeautifulSoup for HTML parsing. The notebook provides examples and code snippets that demonstrate how to extract information from websites and handle large files without running into memory issues.

## Dependencies

The notebook requires the following packages:

- re
- requests
- psutil
- gc
- shutil
- nltk
- bs4
- urllib

## Contents

The notebook is divided into the following sections:

- Regular expressions
- Streams and files
- BeautifulSoup
- Extract all sentences
- Extract URLs from nodes
- Unique file name

## Results

The notebook provides several code snippets that demonstrate how to extract information from websites using regular expressions and BeautifulSoup, as well as how to work with large files without running into memory issues. The insights gained from this notebook include the importance of using regular expressions for pattern searching, using streams instead of RAM-cached files for working with large files, and the benefits of using BeautifulSoup for parsing HTML.

## Usage

To use the notebook, you will need to have the required dependencies installed. You can run the code snippets provided in the notebook to extract information from websites and work with large files. Note that some of the code snippets may take a while to run, especially when dealing with large files or websites. Additionally, when working with URLs, be sure to handle relative links appropriately and avoid trying to convert URLs into filenames.
